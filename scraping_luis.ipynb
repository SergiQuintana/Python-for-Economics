{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bse_logo_textminingcourse](https://bse.eu/sites/default/files/bse_logo_small.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Legality of Scraping\n",
    "\n",
    "#### 1) White Zone\n",
    "\n",
    "\n",
    "<img src=\"./images/api.png\" width=\"300\">\n",
    "\n",
    "-  Legally safe as long as you obtain information from APIs or public databases.\n",
    "\n",
    "#### 2) Dark Zone\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"./images/dark.png\" width=\"300\">\n",
    "\n",
    "-  Entails pretending to be a person. Avoid accepting website policies with a scraper. This applies particularly to activities within the Chinese intranet.\n",
    "\n",
    "#### 3) Grey Zone\n",
    "\n",
    "- Involves pretending to be yourself. Accepting cookies is generally fine, but ensure they do not imply agreement to any internal policy. Using an email to log in is acceptable, but avoid using personal information such as an address, ID, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages for Web Scraping\n",
    "\n",
    "#### Requests\n",
    "\n",
    "- **Function**: Serves to fetch HTML content for webpages. You first make the request and then extract data with beautiful soup. \n",
    "\n",
    "#### BeautifulSoup\n",
    "\n",
    "- **Function**: BeautifulSoup does not simulate browsers. It fetches HTML and transforms it into a BeautifulSoup object, simplifying the extraction of HTML tags.\n",
    "\n",
    "#### Selenium\n",
    "\n",
    "- **Function**: Selenium is used to simulate a browser. It can perform human-like actions within the browser.\n",
    "\n",
    "#### Scrapy\n",
    "\n",
    "- **Function**: Ideal for large-scale projects, Scrapy doesn't use a browser. Sometimes, it may require browser simulation to bypass blocking protocols. It's primarily designed for efficient data extraction.\n",
    "\n",
    "#### Differences\n",
    "\n",
    "- **Use Case Dependence**: The choice among these tools depends on your specific needs.\n",
    "- **Handling JavaScript**: JavaScript runs in the browser. To extract JavaScript-generated content, a browser environment like that provided by Selenium is necessary.\n",
    "\n",
    "#### Handling Blockages\n",
    "\n",
    "- **Cloudflare**: Many websites use Cloudflare to prevent DDoS attacks. Check if a site uses Cloudflare [here](https://checkforcloudflare.selesti.com/).\n",
    "- **Selenium Strategies**:\n",
    "  - `time.sleep()` or `WebDriverWait()` can help bypass blockages.\n",
    "  - For anti-bot protection, `undetected-chromedriver` can be useful. Note that this is only available for Chrome, not Firefox.\n",
    "\n",
    "#### Simulating Human-Like Behavior with Selenium\n",
    "\n",
    "- **Short-Term**: Implement random waiting times or keystroke intervals.\n",
    "- **Long-Term**: Emulate human sleep cycle behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  HTML, Java, JavaScript in the Context of Web Scraping\n",
    "\n",
    "#### HTML (HyperText Markup Language)\n",
    "\n",
    "- HTML is the standard markup language for documents designed to be displayed in a web browser. It describes the structure of web pages using markup.\n",
    "- HTML will be your main nightmare. You want to extract text information cleaning the language to get what you need. \n",
    "\n",
    "All (well formatted) HTML webpages start with a basic structure:\n",
    "\n",
    "```\n",
    "<html>\n",
    "<head>\n",
    "<title> my title <title>\n",
    "<html>\n",
    "``````\n",
    "\n",
    "\n",
    "\n",
    "#### JavaScript\n",
    "\n",
    "   JavaScript is a scripting language that enables interactive web pages. Unlike Java, it is primarily used for client-side web development.\n",
    "\n",
    "\n",
    "## When is JavaScript Rendered?\n",
    "\n",
    "- **During Browsing**: JavaScript is rendered by the browser when a page is loaded or interacted with. This can include actions like clicking, scrolling, or submitting forms.\n",
    "- **Scraping**: For scraping purposes, tools that can execute JavaScript (like Selenium) are necessary to access content that is loaded or altered dynamically by scripts.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Structure of XPath and CSS Selectors\n",
    "\n",
    "When searching for elements in HTML, it's common to use either XPath or CSS selectors. The choice of selector depends on the specific requirements and context of the task. Below is a basic guide to understanding the structure of these selectors.\n",
    "\n",
    "#### Search Hierarchy\n",
    "\n",
    "1. **ID**: \n",
    "   - **Description**: Unique identifier for an element. Not always available.\n",
    "   - **Format**: `id=\"unique_id\"`\n",
    "2. **Class**:\n",
    "   - **Description**: Class name(s) associated with an element.\n",
    "   - **Format**: `class=\"class_name\"`\n",
    "3. **Tag**:\n",
    "   - **Description**: HTML tag (like `div`, `label`, etc.).\n",
    "   - **Format**: `<tag>`\n",
    "4. **Attribute**:\n",
    "   - **Description**: An attribute and its value within an element.\n",
    "   - **Format**: `attribute=\"attribute_value\"`\n",
    "\n",
    "#### XPath\n",
    "\n",
    "- **Basic Structure**:\n",
    "  \n",
    "  ```xpath\n",
    "  //tag[@attribute=\"attribute_value\"][position]\n",
    "\n",
    "The double bar `//` selects all elements that match that path \n",
    "\n",
    "#### CSS\n",
    "\n",
    "You also have CSS selectors that will match elements based on attributes. These are easier but less robust than xpath. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So how do I scrape:\n",
    "\n",
    "\n",
    "- CloudFare protection will block you from doing many requests at a time so this does not necesarely speeds up the process. \n",
    "- More profesional techniques would create cloud services with multiple instances (and thus multiple ips).\n",
    "- Avoid accepting terms of service and potentially emulate human like behavior. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d922f7f9ddec9c8ef74cec7f1e3e1c6e6922ab2a276fa9da4b3e41b7add4671"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
