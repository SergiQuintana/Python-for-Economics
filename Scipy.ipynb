{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciPy\n",
    "\n",
    "SciPy provides algorithms for optimization, integration, interpolation, eigenvalue problems, algebraic equations, differential equations, statistics and many other classes of problems. It is a collection of mathematical algorithms and convenience functions built on `NumPy` . SciPy adds significant power to Python by providing the user with high-level commands and classes for manipulating and visualizing data. As always, visit its [website](https://scipy.org/) to find more information about the package. \n",
    "\n",
    "## Subpackages\n",
    "\n",
    "SciPy is organized into subpackages covering different scientific computing domains. The most relevant for us are:\n",
    "\n",
    "1. Optimize. Contains optimization and root-finding routines. \n",
    "2. Integrate. Integration and differential equaiton solver. \n",
    "3. Interpolate. Interpolation and smoothing splines. \n",
    "\n",
    "## Optimize\n",
    "\n",
    "The `scipy.optimize` package provides several commonly used optimization algorithms. Here we will revise the main functions for constrained and unconstrained optimization. Visit [here](https://docs.scipy.org/doc/scipy/tutorial/optimize.html) to have access to the full list. \n",
    "\n",
    "### scipy.optimize.minimize\n",
    "Minimization of scalar function of one or more variables. See documentation [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html.). As an example, we will now minimize the Rosenbrok function: \n",
    "$$f(x) = \\sum_{i=1}^{N-1}100(x_{i+1}-x_{i}^2) + (1-x_{i})^2$$\n",
    "The minimum is $0$, achieved when $x_i=1$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99999925 0.99999852 0.99999706 0.99999416 0.99998833]\n",
      "  message: Optimization terminated successfully.\n",
      "  success: True\n",
      "   status: 0\n",
      "      fun: 4.581838024995112e-11\n",
      "        x: [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "      nit: 25\n",
      "      jac: [-5.789e-06 -2.823e-06 -2.798e-06 -7.643e-06  5.855e-06]\n",
      " hess_inv: [[ 7.585e-03  1.243e-02 ...  4.613e-02  9.217e-02]\n",
      "            [ 1.243e-02  2.481e-02 ...  9.296e-02  1.856e-01]\n",
      "            ...\n",
      "            [ 4.613e-02  9.296e-02 ...  3.737e-01  7.459e-01]\n",
      "            [ 9.217e-02  1.856e-01 ...  7.459e-01  1.494e+00]]\n",
      "     nfev: 180\n",
      "     njev: 30\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def rosen(x):\n",
    "    \"\"\"The Rosenbrock function\"\"\"\n",
    "    return sum(100.0*(x[1:]-x[:-1]**2.0)**2.0 + (1-x[:-1])**2.0)\n",
    "\n",
    "x0 = np.array([1.3, 0.7, 0.8, 1.9, 1.2])  # Initial Guess! \n",
    "res = minimize(rosen, x0)\n",
    "\n",
    "# We can access the resuts of the optimization problem\n",
    "print(res.x)\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want, we can choose the optmization algorithm. For example, let's try the Nelder-Mead Simplex algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99910115 0.99820923 0.99646346 0.99297555 0.98600385]\n"
     ]
    }
   ],
   "source": [
    "res = minimize(rosen, x0, method='nelder-mead')\n",
    "print(res.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constrained Optimization \n",
    "\n",
    "The minimize function provides algorithms for constrained minimization, namely 'trust-constr' , 'SLSQP' and 'COBYLA'. They require the constraints to be defined using slightly different structures. The method 'trust-constr' requires the constraints to be defined as a sequence of objects LinearConstraint and NonlinearConstraint. Methods 'SLSQP' and 'COBYLA', on the other hand, require constraints to be defined as a sequence of dictionaries, with keys type, fun and jac. \n",
    "\n",
    "Therefore, the way we define the constraints will be sensitive to the optimization algorithm that we are using. \n",
    "\n",
    "As an example let us consider the constrained minimization of the Rosenbrock function:\n",
    "\n",
    "$$ min_{x0,x1} 100(x_1 - x_0^2) + (1-x_0)^2 $$\n",
    "subject to:\n",
    "$$x_0 + 2x_1 \\leq 1 \\\\ \n",
    "x_0^2 + x_1 \\leq 1 \\\\\n",
    "x_0^2 - x_1 \\leq 1 \\\\\n",
    "2x_0 + x_1 = 1 \\\\\n",
    "0 \\leq x_0 \\leq 1 \\\\\n",
    "-0.5 \\leq x_1 \\leq 2 $$\n",
    "\n",
    "This optimization problem has the unique solution $[x_0,x_1] = [0.4149,0.1701]$, for which only the first and fourth constraints are active.  To solve this problem we will be using the Trust-Region Constrained Algorithm.  We will now proceed as following: \n",
    "1. Define the Bounds. \n",
    "2. Define the Linear Constraints. \n",
    "3. Define the NonLinear Constraints. \n",
    "4. Solving the Optimization Problem. \n",
    "\n",
    "#### Defining Bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import Bounds\n",
    "\n",
    "bounds = Bounds([0,-0.5],[1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Linear Constraints:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import LinearConstraint\n",
    "linear_constraint = LinearConstraint([[1, 2], [2, 1]], [-np.inf, 1], [1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Nonlinear Constraints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cons_f(x):\n",
    "    return [x[0]**2 + x[1], x[0]**2 - x[1]]\n",
    "def cons_J(x):\n",
    "    return [[2*x[0], 1], [2*x[0], -1]]\n",
    "def cons_H(x, v):\n",
    "    return v[0]*np.array([[2, 0], [0, 0]]) + v[1]*np.array([[2, 0], [0, 0]])\n",
    "from scipy.optimize import NonlinearConstraint\n",
    "nonlinear_constraint = NonlinearConstraint(cons_f, -np.inf, 1, jac=cons_J, hess=cons_H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solving the optimization problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`gtol` termination condition is satisfied.\n",
      "Number of iterations: 12, function evaluations: 24, CG iterations: 7, optimality: 4.44e-09, constraint violation: 0.00e+00, execution time: 0.029 s.\n",
      "[0.41494531 0.17010937]\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([0.5, 0])\n",
    "res = minimize(rosen, x0, method='trust-constr',\n",
    "               constraints=[linear_constraint, nonlinear_constraint],\n",
    "               options={'verbose': 1}, bounds=bounds)\n",
    "\n",
    "print(res.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice. Solve the following optimization problem: \n",
    "\n",
    "$$min_{x1,x2} x_1^2 + x_2^2 $$\n",
    "subject to\n",
    "$$ 1 \\leq x_1 \\leq 4 \\\\ \n",
    "-3 \\leq 2 x_2 \\leq -2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1. -2.]\n"
     ]
    }
   ],
   "source": [
    "def objective_function(x):\n",
    "\n",
    "    return x[0]**2 + x[1]**2\n",
    "\n",
    "bounds = Bounds([1,-3],[4,-2])\n",
    "\n",
    "x0 = [3,-1.5]\n",
    "\n",
    "res = minimize(objective_function, x0, bounds=bounds)\n",
    "\n",
    "print(res.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root Finder\n",
    "\n",
    "The main function to find the root of a function is `fsolve()`. You can find the documentation [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fsolve.html).  Let's see it in action trying to find a solution to the following system of equations: \n",
    "$$ x_0\\cos{x_1} = 4 \\\\ \n",
    "x_0x_1 - x_1 = 5$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.50409711, 0.90841421])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import fsolve\n",
    "def func(x):\n",
    "    return [x[0] * np.cos(x[1]) - 4,\n",
    "            x[1] * x[0] - x[1] - 5]\n",
    "root = fsolve(func, [1, 1])  # inputs are the system of equations and the initial guess of their roots. \n",
    "root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration\n",
    "\n",
    "There are multiple ways to perform integration using the `scipy.integrate` library. You can find a revision in [here](https://www.geeksforgeeks.org/scipy-integration/). For the porpuse of this class we will just see a couple of examples extracted from the previous link. \n",
    "\n",
    "### Single variable integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n",
      "2.220446049250313e-14\n"
     ]
    }
   ],
   "source": [
    "from scipy.integrate import quad \n",
    "  \n",
    "def f(x): \n",
    "  return 3.0*x*x + 1.0\n",
    "  \n",
    "I, err = quad(f, 0, 1) \n",
    "print(I) # Integral\n",
    "print(err) # Integration error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.010416666666666668, 4.101620128472366e-16)\n"
     ]
    }
   ],
   "source": [
    "from scipy.integrate import dblquad \n",
    "  \n",
    "area = dblquad(lambda x, y: x*y, 0, 0.5,  \n",
    "               lambda x: 0, lambda x: 1-2*x) \n",
    "  \n",
    "print(area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n-dimensional integral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78.12499999999999, 8.673617379884033e-13)\n"
     ]
    }
   ],
   "source": [
    "from scipy.integrate import nquad \n",
    "  \n",
    "  \n",
    "def f(x, y, z): \n",
    "    return x*y*z \n",
    "  \n",
    "  \n",
    "I = nquad(f, [[0, 1], [0, 5], [0, 5]]) \n",
    "print(I) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>TIP!</b> If you are trying to apply integration techniques to your coude, you might want to learn about Gaussian Quadratures. </div>\n",
    "\n",
    "Visit the link [here](https://en.wikipedia.org/wiki/Gaussian_quadrature) for more information about it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
